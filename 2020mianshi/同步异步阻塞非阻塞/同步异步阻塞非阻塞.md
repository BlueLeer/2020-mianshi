# 同步异步阻塞非阻塞

> 博文参考: <https://mp.weixin.qq.com/s/EVequWGVMWV5Ki2llFzdHg>



## 同步和异步

### 同步

所谓同步，就是协同步调。既然叫协同，所以至少要有2个以上的事务存在。协同的结果就是：

**多个事务不能同时运行，必须一个一个的来，上一个事务结束后，下一个事务才能进行。**

那当一个事物正在进行时，其它事物都在干嘛呢？

严格来讲这个并没有要求，但一般都是处于一种“等待”的状态，因为通常后面事物的正常进行都需要依赖前面事物的结果或前面事物正在使用的资源。

因此，可以认为，同步更希望关注的是从宏观整体来看，多个事物是一种逐个逐个的串行化关系，绝对不会出现交叉的情况。  

所以，自然也不太会去关注某个瞬间某个具体事物是处于一个什么状态。

把这个理论应用的出神入化的非“排队”莫属。凡是在**资源少需求多的场景下都会用到排队。**

除了这种由于资源导致的同步外，还存在一种**由于逻辑上的先后顺序导致的同步**。

比如，先更新代码，然后再编译，接着再打包。这些操作由于后一步要使用上一步的结果，所以只能按照这种顺序一个一个的执行。  



关于同步还需知道两个小的点：

一是范围，并不需要在全局范围内都去同步，只需要在某些关键的点执行同步即可。

比如食堂只有一个卖饭窗口，肯定是同步的，一个人买完，下一个人再买。但吃饭的时候也是一个人吃完，下一个人才开始吃吗？当然不是啦。

二是粒度，并不是只有大粒度的事物才有同步，小粒度的事物也有同步。



只不过小粒度的事物同步通常是天然支持的，而大粒度的事物同步往往需要手工处理。

比如两个线程的同步就需要手工处理，但一个线程里的两个语句天然就是同步的。



### 异步

所谓异步，就是步调各异。既然是各异，那就是都不相同。所以结果就是：

**多个事物可以你进行你的、我进行我的，谁都不用管谁，所有的事物都在同时进行中。**  



## 阻塞和非阻塞

**所谓阻塞，指的是阻碍堵塞。它的本意可以理解为由于遇到了障碍而造成的动弹不得。**

**所谓非阻塞，自然是和阻塞相对，可以理解为由于没有遇到障碍而继续畅通无阻。**

对这两个词最好的诠释就是，当今中国一大交通难题，堵车：

汽车可以正常通行时，就是非阻塞。一旦堵上了，全部趴窝，一动不动，就是阻塞。



因此阻塞关注的是不能动，非阻塞关注的是可以动。



不能动的结果就是只能等待，可以动的结果就是继续前行。

因此和阻塞搭配的词一定是等待，和非阻塞搭配的词一定是进行。

**回到程序里，阻塞同样意味着停下来等待，非阻塞表明可以继续向下执行。**



## 同步/异步和阻塞/非阻塞 两两组合

所谓同步/异步，关注的是**能不能同时开工**。

所谓的阻塞/非阻塞，关注的是**能不能动**。



通过推理进行组合：

同步阻塞，不能同时开工，也不能动。只有一条小道，一次只能过一辆车，可悲的是还TMD的堵上了。

同步非阻塞，不能同时开工，但可以动。只有一条小道，一次只能过一辆车，幸运的是可以正常通行。

异步阻塞，可以同时开工，但不可以动。有多条路，每条路都可以跑车，可气的是全都TMD的堵上了。

异步非阻塞，可以工时开工，也可以动。有多条路，每条路都可以跑车，很爽的是全都可以正常通行。

是不是很容易理解啊。其实它们的关注点是不同的，只要搞明白了这点，组合起来也不是事儿。

回到程序里，把它们和线程关联起来：

**同步阻塞，相当于一个线程在等待。**

**同步非阻塞，相当于一个线程在正常运行。**

**异步阻塞，相当于多个线程都在等待。**

**异步非阻塞，相当于多个线程都在正常运行。**



## IO

IO指的是：读入/写出数据的过程，和**等待**读入/写出数据的过程。（很多时候我都忘记考虑 等待读入/写出也属于IO的范畴）。一旦拿到数据以后，就不叫IO了，它就变成数据操作了。

拿网络IO来说，**等待的过程就是数据从网络到网卡再到内核空间**。**读写的过程就是内核空间和用户空间的相互拷贝。**

所以IO就包括两个过程，**一个是等待数据的过程，一个是读写（拷贝）数据的过程**。而且还要明白，一定**不**能包括操作数据的过程。



### 阻塞IO 和 非阻塞IO

#### 阻塞IO

应用程序都是运行在用户空间的，所以它们能操作的数据也都在用户空间。按照这样子来理解，只要数据没有到达用户空间，用户线程就操作不了。

如果此时用户线程已经参与，那它一定会被阻塞在IO上。这就是常说的阻塞IO。用户线程被阻塞在等待数据上或拷贝数据上。

#### 非阻塞IO

非阻塞IO就是用户线程不参与以上两个过程，即数据已经拷贝到用户空间后，才去通知用户线程，一上来就可以直接操作数据了。

用户线程没有因为IO的事情出现阻塞，这就是常说的非阻塞IO。



### 同步、异步、阻塞、非阻塞和IO的搭配

#### 同步IO（同步阻塞IO）

同步IO=同步阻塞IO

根据同步的意思，同步IO是指发出同步请求以后，必须拿到数据以后才可以继续往下执行。

按照程序的表现形式又分为2种： 

1. 待等待数据或者拷贝数据的过程中，线程都在阻塞，这就是同步阻塞IO
2. 在等待数据的过程中，线程采用死循环式轮询，在拷贝数据的过程中，线程在阻塞，这其实还是同步阻塞IO。

> 网上很多文章把第二种归为同步非阻塞IO，这肯定是**错误**的，它一定是阻塞IO，因为拷贝数据的过程，线程是阻塞的。
>
> 严格来讲，在IO的概念上，同步和非阻塞是相悖的，同步IO，那么一定就是同步阻塞IO。因为同步IO意味着必须要先拿到数据才能继续往下操作，因此它必须是阻塞的。
>
> 非阻塞IO意味着发起IO请求后，可以继续往下执行。说明后续执行不依赖与IO数据，所以它肯定不是同步的。例如程序执行过程中要把执行日志写入到日志文件当中，后面的程序逻辑是不依赖于日志是否写入成功这一逻辑的。



#### 异步IO

按照上文中对异步的理解，异步IO是指发起IO请求后，不用拿到IO的数据就可以继续执行。

用户线程的继续执行，和操作系统准备IO数据的过程是同时进行的，因此才叫做异步IO。

一言以蔽之：程序在执行IO操作过程中，不用停下来等待，继续执行。

按照IO数据的两个过程，又可以分为两种：

* 异步阻塞IO

  在**等待数据**的过程中，用户线程继续执行，在**拷贝数据**的过程中，线程在阻塞，这就是**异步阻塞IO**。

  用户线程没有参与数据等待的过程，所以它是异步的。但用户线程参与了数据拷贝的过程，所以它又是阻塞的。合起来就是异步阻塞IO。

* 异步非阻塞IO

  在**等待数据**的过程中，和**拷贝数据**的过程中，用户线程都在继续执行，这就是**异步非阻塞IO**。

  用户线程既没有参与等待过程也没有参与拷贝过程，所以它是异步的。当它接到通知时，数据已经准备好了，它没有因为IO数据而阻塞过，所以它又是非阻塞的。合起来就是异步非阻塞IO。

> 在netty中异步IO是怎么实现的呢?
>
> * 异步阻塞IO
>
>   ...
>
> * 异步非阻塞IO
>
>   ...



## Java中的I/O模型

### BIO

BIO，即**Blocking IO**，阻塞I/O模型是常见的I/O模型，通常我们使用的`InputStream/OutputStream`都是基于阻塞IO模型。通常都是每一个IO操作都单独的创建一个线程（为什么一个连接就开启一个线程来处理呢，），该线程处理该连接的读和写，并且读和写是不能同时发生的。

### NIO

NIO可以称为New IO，也可以称为Non-Blocking IO，它比Java旧的阻塞IO在性能上要高出许多（这里需要注意的是，并不是说阻塞IO性能一定比非阻塞IO性能低，因为在阻塞IO中，如果我们对每一个连接都开启一个线程来处理该连接的读写，那也是很快的，但是线程肯定不是无限制创建的，连接多了，BIO就处理不过来了。）

NIO中关键的几个类：

* ByteBuffer

  NIO的数据传输是基于缓冲区的，ByteBuffer正是NIO数据传输中所使用的缓冲区抽象。ByteBuffer支持在堆外分配内存，并且尝试避免在执行I/O操作中的多余复制。一般的IO操作都需要进行系统调用，这样先切换到内核态，内核态要先从文件读取数据到它的缓冲区，只有等数据准备完毕以后，才会从内核态把数据写到用户态（如果想要避免这个额外的内核操作，可以通过使用mmap（虚拟内存映射）的方式来让用户态直接操作文件），数据到达用户态以后还要进行数据的拷贝。所谓的阻塞IO就是指用户线程参与到了数据的等待或者拷贝上，它一定会被阻塞住。

* Channel

  它类似于文件描述符，简单的来说它代表了一个实体（如一个硬件设备、文件、Socket或者一个能够执行一个或者多个不同的I/O操作的程序组件），你可以**从一个Channel中读取数据到缓冲区**，也可以**将一个缓冲区中的数据写入到Channel**。

* Selector

  选择器是NIO实现的关键，NIO采用的是I/O多路复用的方式来实现非阻塞，Selector通过在一个线程中监听每个Channel的IO事件来确定有哪些已经准备好进行IO操作的Channel，如果检查到一个channel数据已经到达用户态，就可以来将交给一个线程去处理数据拷贝操作。这种方式避免了等待IO操作准备数据时的阻塞，使用较少的线程便可以处理许多连接，减少了线程切换与维护的开销。（例如有这样一个模型，一个线程通过轮询的方式去监听一个Socket的server端是否有线程等待连接，如果有客户端等待连接，该线程就处理连接；另一个线程去监听数据是否已经准备好了（数据从网络或文件经由内核态到达用户态），如果已经准备好了，那么将该连接的数据读取操作交给线程池中的线程来处理）

> 延伸：Tomcat是如何处理多个请求的？
>
> Tomcat创建线程池的方法在AbstractEndpoint类中，它有三个子类，分别用来实现tomcat connector的三种运行模式：BIO、NIO、APR。这里先来看看BIO运行模式进行分析。Tomcat启动的时候，会创建一个线程池，这个线程池主要是处理请求任务的。它的运作模式和线程池是一样的（当运行线程小于corePoolSize时，请求来了以后，线程池将创建新的线程来处理任务，如果线程数量等于或者多于corePoolSize，则将请求放入队列，如果队列满了，继续创建线程，直到达到maximumPoolSize，此时再来任务就会按照线程池的拒绝策略来拒绝任务。）在BIO模式下，当连接达到maxConnections时，请求将不会被socket接受，而是进入TCP的**完全连接**队列中（注意：不是线程池中的队列），当队列中连接数量大于acceptCount值时，则报“**connection refused**”错误。我们可以看到，虽然线程池技术提高了性能，缩短了请求响应的时间，同时防止了突发性大量请求引起的资源耗尽，但是它本质上还是一个线程处理一个请求。线程池结合NIO技术，让少量的线程处理大量的请求，将极大的提高并发能力，在**tomcat 6**以后，已经实现了这一技术，只要将server.xml配置成如下即可:
>
> ```xml
> <Connector port="8080" protocol="org.apache.coyote.http11.Http11NioProtocol" 
> connectionTimeout="20000" redirectPort="8443"/>
> ```
>
> 并且，springboot中集成tomcat中的配置信息如下：
>
> ```java
> public static final String DEFAULT_PROTOCOL = "org.apache.coyote.http11.Http11NioProtocol";
> ```
>
> 可以看到，默认是NIO模式的。