## HashMap

1. 实现原理：它是基于数组实现的，根据key值的hash对数组长度取模，得到数组的下标，然后取出数组中对应的元素
2. 因为是基于数组的，因此需要考虑：hash算法及其优化，寻址算法的优化，hash冲突怎么解决、数组扩容怎么实现的、扩容以后要重hash，它是怎么优化的



### 1.hash算法

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

可以看到，如果key是null，那么取得hash值为0，如果不为null，则用hashcode和hashcode右移16位以后的值进行亦或运算（其实也就是hashcode的高十六位和低十六位进行了抑或运算）

```` 
1111 1111 1111 1111 1101 0110 1100 0001 -> hashcode
0000 0000 0000 0000 1111 1111 1111 1111 -> h>>>16
1111 1111 1111 1111 0010 1001 0011 1110 -> ^亦或运算

例如，有这么2个hash（hashcode），他们没有经过hash优化：
1111 1111 1111 1111 1101 0110 1100 0001
1111 1111 1111 1110 1101 0110 1100 0001
在进行（hash & （n-1））后
0000 0000 0000 0000 0000 0000 0000 1111 ：这里是n-1
结果都是：
0000 0000 0000 0000 0000 0000 0000 0001
造成了hash冲突。
如果先进行hash优化，则新的hash值为：
1111 1111 1111 1111 1101 0110 1100 0001
0000 0000 0000 0000 1111 1111 1111 1111
-------------------------------------------^
1111 1111 1111 1111 0010 1001 0011 1110

1111 1111 1111 1110 1101 0110 1100 0001
0000 0000 0000 0000 1111 1111 1111 1110
-------------------------------------------^
1111 1111 1111 1110 1101 0110 1100 1111

两个值计算 hash & (n-1)以后的值就不同了:
````

hash算法为什么要先把hashcode值进行高16位和低16位的亦或运算呢？**我们知道，一般来说n-1都是比较小的，参与到^（异或）运算的主要是hash值的低16位，因为这样优化以后，使得新的hash值低16位同时具备了原hash值高16位和低16位的特征，这样就增加了随机性减少hash冲突。**其实是要根据寻址算法优化结合着来说的，因为后面用到了与操作，而参与运算的主要是低16位，因此低16位就要融合高低16位的特征，从而减少hash冲突

### 2.寻址算法优化

(n-1)&hash，n代表数组的长度。只要保证n是2的n次方，那么，就能保证 hash % n 等效于 hash & （n-1）

```java
hashcode:也就是54977
1111 1111 1111 1111 1101 0110 1100 0001
数组长度(n):16
    取模以后得到:1
        
hash:
1111 1111 1111 1111 0010 1001 0011 1110
(n-1):
0000 0000 0000 0000 0000 0000 0000 1111
(n-1)&hash: 得到14
0000 0000 0000 0000 0000 0000 0000 1110
hash % n得到：
0010100100111110转化为10进制为：10558,10558%16=14
```

我们知道位运算肯定是比%运算快的。也就是说取模运算的效率差一些，为了优化这个寻址过程只要保证数组长度为2的n次方，然后对hash和（n-1）进行&（与）运算，就能达到hash%n的效果。

### 3.HashMap是如何解决hash碰撞问题的？

不同的key通过hash&（n-1）运算过后得到数组的下标可能是一样的，这就引起了hash碰撞。HashMap中对于解决hash碰撞的方法是通过**拉链法**：将数组和链表结合，也就是说创建一个链表数组，数组中的每一格就是一个链表，当有hash冲突的时候，将冲突的值加到链表即可。在JDK1.8之后，如果链表的长度大于阈值（默认为8）时，就会将链表转化成红黑树，以减少搜索时间（搜索时间为 O（logn））。另外值得注意的是：链表转化成红黑说之前，是要先判断的，当数组长度小于64的时候，会优先进行扩容，而不是转换成红黑树（因为扩容以后，n的值变了，（n-1）&hash可能得到不同的数组下标）。

> 另外，TreeMap，TreeSet以及JDK1.8之后的HashMap底层都用到了红黑树。红黑树通过旋转变色来维持它的平衡性，防止某些情况下二叉搜索树退化成一个链表或者倾斜度很大的二叉树。



### 4. 说说为什么HashMap数组初始大小是16？

因为16是2的4次方，这样在优化寻址的时候能派上用场，能使得 hash&(n-1)达到hash%n的效果。另外，其实我们即使指定了HashMap容量的初始值，它也会通过运算，计算出大于这个值而又满足2的n次方的最小值，例如我们指定了容量为10，那么最后计算以后容量是16了。

另外，在`hash&（n-1）`运算的过程中，如果容量是2的n次方，那么（n-1）得到的值的二进制都是1，在与运算过程中避免了有些数组下标永远用不到的情况，例如：如果我们的数组容量为11，那么（n-1）二进制为：1010，在进行与操作以后，1001（9）、0111（7）等这些数组中的位置永远没有值，这样就会极大的浪费空间了。还能有效的减少hash碰撞。



### 5.说说HashMap是如何进行扩容的？

当HashMap中的元素越来越多的时候，碰撞的几率就会越来越高（因为数组的长度是固定的），所以为了提高查询效率，就要对HashMap的数组进行扩容。**原数组中的数据必须重新计算其在新数组中的位置，并存放进去，这就是resize**。

什么时候进行扩容呢？

当HashMap中的**元素个数超过数组大小*loadFactor（负荷系数，默认为0.75）**时，就要对HashMap的数组进行扩容，然后重新计算每个元素在新数组中的位置，而这是一个非常消耗性能的操作，因为涉及到数组下标运算，还有元素的移动等。所以，如果我们能够预知HashMap中将要存储元素个数的时候，通过预设`initialCapacity`能够有效提高HashMap的性能。比如说，我们预知HashMap将要存储的元素为1000个左右：

```shell
X * 0.75 >= 1000
解得:x >= 1333
```

我们就可以指定为1333了，我们指定了初始容量以后，在创建hashmap对象的时候，它会自动找到大于该初始容量而又满足2的n次方的最小值，也就是2048。

扩容以后，根据数组大小，结合hash值重新计算数组下标值，判断该下标值二进制结果中是否多出一个bit的1，如果没多，那么就是原来的index，如果多了出来，那么就是oldIndex+oldCap，通过这个方式，也避免了对新数组大小重新取模。